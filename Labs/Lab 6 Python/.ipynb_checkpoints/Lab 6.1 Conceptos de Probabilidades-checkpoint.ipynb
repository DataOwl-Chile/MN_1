{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"DataOwl\" width=150 src=\"http://gwsolutions.cl/Images/dataowl.png\", align=\"left\", hspace=0, vspace=5></p>\n",
    "\n",
    "<h1 align=\"center\">Probabilidades</h1>\n",
    "\n",
    "<h4 align=\"center\">Concepto de integral definida y Métodos Monte-Carlo</h4>\n",
    "<pre><div align=\"center\"> La idea de este notebook es que sirva para iniciarse en conceptos\n",
    "básicos del Probabilidades, Cálculo Integral y los métodos disponibles\n",
    "para la generación de datos pseudo-aleatorios.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "El estudio de las Probabilidades ha sido amplio en la historia de las matemáticas, pero su sistematización formal es un campo relativamente moderno, enmarcado dentro de un área más general denominado **Teoría de la Medida**. En lo concerniente al curso, vale la pena saber algunos conceptos generales relacionados con esta disciplina.\n",
    "\n",
    "Supongamos que tenemos que realizar un experimento, por ejemplo, un censo en toda una cuadra. Podríamos querer saber qué tan probable es que nos encontremos con al menos $5$ domicilios deshabitados. En este caso, tenemos un conjunto de objetos de estudio (los domicilios) del cual podemos extraer muestras. Por ello, a éste se le conoce como **espacio muestral**, denotado usualmente por $\\Omega$. Además, el que $5$ domicilios estén deshabitados corresponde a una propiedad que satisface un subconjunto del espacio muestra. A esta propiedad se le conoce como **evento**.\n",
    "\n",
    "Es necesario hacer hincapié en que un evento corresponde a un conjunto definido por una propiedad, es decir,\n",
    "\n",
    "$$A=\\left\\{x\\in \\Omega\\ |\\ p(x)\\right\\}$$\n",
    "\n",
    "Cuando se desea estimar la probabilidad de que ocurra un evento, la principal regla de cálculo es considerar todos los casos favorables al evento que nos interesa, dividido por la cantidad de casos totales que contiene el espacio muestral. De este modo, se define la probabilidad del evento $A$ como\n",
    "\n",
    "$$\\mathbb{P}(A)=\\frac{\\#\\{x\\in A\\}}{\\#\\{x\\in\\Omega\\}}$$\n",
    "\n",
    "En este caso, $\\mathbb{P}$ representa una forma de medir el tamaño del conjunto $A$, relativo al tamaño del espacio muestral. Se le suele llamar **medida de probabilidad** del evento $A$. En un contexto en que se conoce los experimentos a realizar, el espacio $\\Omega$ y la función $\\mathbb{P}$, se dice que operamos en un **espacio de probabilidad**, donde $\\mathbb{P}$ es la ley o **función distribución** en $\\Omega$.\n",
    "\n",
    "Como $A\\subseteq\\Omega$, es trivial que $0\\le\\mathbb{P}\\le1$. Sin embargo, la forma de medir el tamaño de $A$ no siempre es sencilla. Ni siquiera saber determinar el tamaño de $\\Omega$ es fácil, puesto que depende del tipo de experimento que queramos poner a prueba. Para esta parte del curso, se dará una lista de problemas para los que sí se sabe cómo medir estas probabilidades, y se introducirán algunos conceptos útiles para su estudio.\n",
    "\n",
    "## 2. Conceptos de conjuntos\n",
    "\n",
    "Como las probabilidades operan sobre conjuntos y sus \"tamaños\", es necesario tener algunas nociones de cómo se comporta una medida de probabilidad $\\mathbb{P}$ en relación con operaciones de conjuntos. La primera de ellas, corresponde a la idea de conjuntos disjuntos, que se da cuando dos conjuntos no tienen elementos en común. Esto se asocia a cuando dos eventos son mutuamente excluyentes, como podría ser obtener un número par y obtener $3$ al lanzar un dado. En este caso, se tiene que\n",
    "\n",
    "$$\\mathbb{P}(A\\dot\\cup B)=\\mathbb{P}(A)+\\mathbb{P}(B)$$\n",
    "\n",
    "Más generalmente, si tenemos una colección de eventos disjuntos, la probabilidad de que se dé la unión de éstos es igual a la suma de las probabilidades individuales. \n",
    "\n",
    "La expresión para simbolizar los elementos en común que tienen dos conjuntos es la de la intersección entre ellos, $A\\cap B$. El caso en que no hay intersección está definido como $A\\cap B=\\varnothing$, el conjunto vacío. Además, la sustracción de dos conjuntos, denotada por $A\\setminus B$, es el conjunto que resulta de quitar los elementos de $B$ que hay en $A$ . Luego, siempre es posible separar la unión de dos conjuntos en tres conjuntos disjuntos:\n",
    "\n",
    "$$A\\cup B=(A\\setminus B)\\ \\dot\\cup\\ (B\\setminus A)\\ \\dot\\cup\\ (A\\cap B)$$\n",
    "\n",
    "Por lo visto anteriormente, se tendrá que\n",
    "\n",
    "$$\\mathbb{P}(A\\cup B)=\\mathbb{P}(A)\\ +\\ \\mathbb{P}(B)\\ -\\ \\mathbb{P}(A\\cap B)$$\n",
    "\n",
    "Además, para efectos prácticos, vale la pena notar que $\\mathbb{P}(A\\cup B)\\le\\mathbb{P}(A)+\\mathbb{P}(B)$. También en muchas situaciones, dos eventos pueden ser independientes, lo que significa que el hecho de que uno ocurra no afecta en la ocurrencia del otro, y viceversa. Esto se da, por ejemplo, en el evento de obtener \"cara\" al lanzar una moneda y obtener un número primo al escoger una carta de una baraja. En tal caso, la intersección de dos eventos se interpreta como la ocurrencia de ambos, y para eventos que son independientes se cumple que\n",
    "\n",
    "$$\\mathbb{P}(A\\cap B)=\\mathbb{P}(A)\\cdot\\mathbb{P}(B)$$\n",
    "\n",
    "Junto con lo anterior, debe cumplirse que la probabilidad de que el resultado del experimento pertenezca al espacio muestral sea igual a $1$, que representa el total de la probabilidad. Es decir,\n",
    "\n",
    "$$\\mathbb{P}(\\Omega)=1$$\n",
    "\n",
    "Por lo tanto, para satisfacer tanto esto como lo anterior, debe cumplirse que\n",
    "\n",
    "$$\\mathbb{P}(A^{\\textrm{c}})=1-\\mathbb{P}(A)$$\n",
    "\n",
    "## 3. Variable aleatoria\n",
    "\n",
    "Cuando pensamos en un experimento y en la probabilidad de que ocurra algún evento en éste, tenemos que expresarlo de forma matemática. En general, se puede pensar que el experimento responde a una función cuya expresión no conocemos a priori, pero sí el resultado que esperamos de ella. Además, dicha función podemos describirla de forma literal y, basados en algún argumento de conteo o de proporción, dotarla de una forma matemática.\n",
    "\n",
    "Esta función es llamada **variable aleatoria**, denotada por $X:\\Omega\\longrightarrow\\mathbb{R}$, cuyo dominio es el espacio muestral. Mediante esta función, se define la probabilidad de que el experimento devuelva ciertos valores como la probabildad de que la variable aleatoria pertenezca al conjunto de dichos valores, de forma que\n",
    "\n",
    "$$\\mathbb{P}_X(A)=\\mathbb{P}(X\\in A)=\\mathbb{P}\\left(\\left\\{\\omega\\in\\Omega\\ |\\ X(\\omega) \\in A\\right\\}\\right)$$\n",
    "\n",
    "Debe entenderse que es la variable aleatoria $X$ la que dará forma a la medida de probabilidad que usaremos, y dar con una representación adecuada de dicha función es una de las mayores dificultades que se presenta a la hora de realizar un estudio probabilístico. Veremos los ejemplos más clásicos de variable aleatoria, con expresiones derivadas de ella que serán de utilidad para los casos expuestos. En un futuro se verá casos más complejos.\n",
    "\n",
    "## 4. Función de probabilidad discreta\n",
    "\n",
    "Se entiende por **conjunto discreto** cualquier conjunto cuyos elementos pueden ser enumerados por los números naturales. Ejemplos de conjuntos discretos son cualquier conjunto finito, el conjunto de los números naturales, los números enteros y los números racionales.\n",
    "\n",
    "Dentro de estos conjuntos, se puede definir una **función de densidad de probabilidad** (o pdf, por *probability density function*), que representa qué eventos tienen mayor probabilidad de ocurrir. Se suele representar por $f_X(k)$, donde $k$ es el valor de la variable aleatoria $X$ para el cual se quiere conocer la probabilidad, y que puede tomar valores en un conjunto $\\Omega$ discreto. Es decir,\n",
    "\n",
    "$$\\mathbb{P}(X=k)=f_X(k)$$\n",
    "\n",
    "Es claro, por definición, que $f_X$ debe ser una función no negativa y que debe cumplirse que\n",
    "\n",
    "$$\\sum_{k\\in\\Omega}f_X(k)=1$$\n",
    "\n",
    "Además, para $k\\notin\\Omega$, $f_X(k)=0$, ya que la probabilidad de que ocurra un evento que no está previsto en el espacio muestral debe ser nula.\n",
    "\n",
    "Por otro lado, se puede definir la **función de distribución** (o CDF, por *cumulative distribution function*) como la acumulación de probabilidad de $X$. Se la suele denotar por $F_X(k)$, y está dada por\n",
    "\n",
    "$$F_X(k)=\\mathbb{P}(X\\le k)=\\sum_{i\\le k}f_X(i)$$\n",
    "\n",
    "Es necesario mencionar que una medida de probabilidad queda determinada tanto por la pdf como por la CDF, por lo que hablar de densidad o distribución en un mismo contexto no hará diferencia.\n",
    "\n",
    "### 4.1 Distribución uniforme discreta\n",
    "\n",
    "Es, tal vez, la distribución más sencilla de las que veremos. Básicamente, cuando se tiene un experimento con $n$ posibles resultados entre números enteros $a$ y $b$, todos equiprobables, la variable aleatoria $X$ dada por \"la probabilidad de obtener el valor $k$\" tiene por pdf\n",
    "\n",
    "$$f_X(k) =  \\left\\{ \\begin{matrix}\n",
    "\\frac{1}{n} & , & a\\le k\\le b\\\\\n",
    "0 & , & \\sim\\end{matrix} \\right.$$\n",
    "\n",
    "Se denota $X\\sim\\textrm{U}(a,b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerías\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Distribución de Bernoulli\n",
    "\n",
    "Si un experimento sólo tiene dos posibles resultados y se tiene una variable aleatoria $X$ dada por el evento \"obener resultado1 con una realización del experimento\" (similar a \"obener cara en un lanzamiento de moneda\"), tenemos que la pdf está dada por\n",
    "\n",
    "$$f_X(k) =  \\left\\{ \\begin{matrix}\n",
    "p & , & k=\\textrm{éxito}\\\\\n",
    "1-p & , & k=\\textrm{fracaso}\\end{matrix} \\right.$$\n",
    "\n",
    "Es necesario hacer notar que la probabilidad $p$ está dada para una ocurrencia particular, y suele asociarse con un \"éxito\". Además, una vez que se identifica el resultado que da un éxito, se puede asignar el valor $k=0$ al fracaso y $k=1$ al éxito. Así, una variable aleatoria con distribución de Bernoulli se denota por $X\\sim\\textrm{Ber}(p)$, con $p$ la probabilidad de éxito en ese experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Distribución Binomial\n",
    "\n",
    "Supongamos que ahora tenemos el mismo experimento en donde sólo podemos obtener dos resultados, un éxito con probabilidad $p$ y un fracaso con probabilidad $1-p$, solo que esta vez queremos modelar la cantidad de éxitos que tendremos si repetimos el experimento $n$ veces. Esto define la distribución binomial, donde la variable aleatoria $X$ se describe como \"la probabilidad de obtener $k$ éxitos en $n$ experimentos donde la probabilidad de un éxito es $p$\". La pdf estará dada por\n",
    "\n",
    "$$f_X(k) =  \\left\\{ \\begin{matrix}\n",
    "\\binom{n}{k}p^k(1-p)^{n-k} & , & 0\\le k\\le n\\\\\n",
    "0 & , & \\sim\\end{matrix} \\right.$$\n",
    "\n",
    "Se denota $X\\sim\\textrm{B}(n,p)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Distribución Geométrica\n",
    "\n",
    "Si, por el contrario al caso anterior, deseamos modelar la probabilidad de pasar por una cantidad de fracasos antes de obtener un éxito en nuestro experimento, utilizaremos la distribución geométrica, donde ahora la variable aleatoria $X$ se enuncia como \"la probabilidad de tener que pasar por $k$ fracasos para obtener el primer éxito\". Su pdf es\n",
    "\n",
    "$$f_X(k) =  \\left\\{ \\begin{matrix}\n",
    "p(1-p)^k & , & k\\in\\mathbb{N}\\\\\n",
    "0 & , & \\sim\\end{matrix} \\right.$$\n",
    "\n",
    "y se denota $X\\sim\\textrm{Geo}(p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Distribución Binomial negativa\n",
    "\n",
    "Como extensión de la distribución geométrica, podríamos querer modelar la probabilidad de pasar por una cantidad de fracasos antes de obtener una cantidad determinada de éxitos en nuestro experimento, para lo cual se aplica la distribución binomial negativa, donde ahora la variable aleatoria $X$ se enuncia como \"la probabilidad de tener que pasar por $k$ experimentos para obtener $r$ éxitos\". Su pdf está dada por\n",
    "\n",
    "$$f_X(k) =  \\left\\{ \\begin{matrix}\n",
    "\\binom{k+r-1}{k}p^r(1-p)^{k} & , & k\\in\\mathbb{N}\\\\\n",
    "0 & , & \\sim\\end{matrix} \\right.$$\n",
    "\n",
    "y se denota por $X\\sim\\textrm{BN}(r,p)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Distribución de Poisson\n",
    "\n",
    "Para terminar con las distribuciones discretas, vemos qué ocurre con la variable aleatoria $X$ dada por \"la probabilidad de que un evento ocurra cierta cantidad de veces en el tiempo o espacio, dado que la frecuencia promedio de ocurrencias $\\lambda$ es conocida\". En ese caso, la pdf es\n",
    "\n",
    "$$f_X(k) =  \\left\\{ \\begin{matrix}\n",
    "\\frac{\\lambda^ke^{-\\lambda}}{k!} & , & k\\in\\mathbb{N}\\\\\n",
    "0 & , & \\sim\\end{matrix} \\right.$$\n",
    "\n",
    "y se denota por $X\\sim\\textrm{Pois}(\\lambda)$. Es necesario notar que, como $\\lambda$ es una medida de frecuencia con unidad de medida dada, una transformación en el rango de tiempo en que se quiere medir la probabilidad implica una transformación en $\\lambda$ apropiada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Función de probabilidad continua\n",
    "\n",
    "Supongamos ahora que la variable aleatoria con la que trabajamos puede tomar valores en un intervalo real, entre $a$ y $b$, siendo $a<b$ (eventualmente, de valor $\\pm\\infty$). Al haber \"tantos\" valores posibles para cualquier variable aleatoria de esta naturaleza, la probabilidad de que ocurra exactamente uno sólo de estos valores es despreciable, es decir\n",
    "\n",
    "$$\\mathbb{P}(X=x)=0$$\n",
    "\n",
    "De este modo, la pdf no adquiere el sentido que antes tenía, pues la evaluación puntual siempre dará el resultado anterior. Sin embargo, puede aportar información de **cómo se concentra** la probabilidad de ocurrencias. La probabilidad se interpretará como el área que yace bajo esta pdf, lo cual define la CDF como\n",
    "\n",
    "$$\\mathbb{P}(X\\le x)=\\int_{-\\infty}^xf_X(t)dt$$\n",
    "\n",
    "Gracias a lo anterior, se puede deducir que\n",
    "\n",
    "$$\\mathbb{P}(a\\le X\\le b)=\\int_{a}^bf_X(t)dt\\qquad\\textrm{y}\\qquad \\int_{-\\infty}^{\\infty}f_X(t)dt=1$$\n",
    "\n",
    "Por ende, cualquier función continua no negativa que satisfaga lo anterior, es susceptible de representar una probabilidad. Como en este curso no se pide el requisito de saber cómo se calcula una integral como la anterior, se abordará este asunto desde el punto de vista numérico en el siguiente laboratorio por dos vertientes: la aproximación numérica clásica y los métodos Monte-Carlo.\n",
    "\n",
    "### 5.1 Distribución uniforme continua\n",
    "\n",
    "Similarmente con el caso discreto, esta distribución modela un fenómeno donde todos los resultados son igualmente probables, con la diferencia en que dichos resultados pueden pertenecer a todo un intervalo. Su pdf está dada por\n",
    "\n",
    "$$f_X(x) =  \\left\\{ \\begin{matrix}\n",
    "\\frac{1}{b-a} & , & x\\in[a,b]\\\\\n",
    "0 & , & \\sim\\end{matrix} \\right.$$\n",
    "\n",
    "De este modo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Distribución exponencial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Distribución normal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "**1.-** Sea $\\vec{v}\\in\\mathbb{R}^n$ un vector. Su matriz de Vandermode se define como\n",
    "$$A_{i,j}=v_i^{n-j}\\qquad 1\\le i,j\\le n$$\n",
    "Defina una función que tome como argumento un vector (o una lista) y que retorne su matriz de Vandermode.\n",
    "\n",
    "**2.-** Intente definir una función que calcule el determinante de una matriz $A$, teniendo en cuenta la recursividad vista.\n",
    "\n",
    "**3.-** Para futuras clases, puede ser útil tener instalada la librería Scikit-Learn en su ambiente virtual. Para obenerla, en su terminal (Anaconda Prompt) ejecute el comando\n",
    "\n",
    "```cmd\n",
    "pip install -U scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
