{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"DataOwl\" width=150 src=\"http://gwsolutions.cl/Images/dataowl.png\", align=\"left\", hspace=0, vspace=5></p>\n",
    "\n",
    "<h1 align=\"center\">Probabilidades</h1>\n",
    "\n",
    "<h4 align=\"center\">Concepto de integral definida y Métodos Monte-Carlo</h4>\n",
    "<pre><div align=\"center\"> La idea de este notebook es que sirva para iniciarse en conceptos\n",
    "básicos del Probabilidades, Cálculo Integral y los métodos disponibles\n",
    "para la generación de datos pseudo-aleatorios.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidades\n",
    "\n",
    "## 6. Momentos de una distribución\n",
    "\n",
    "En principio, dado un estudio en el cual haya información recolectada, podríamos no saber muy bien qué tipos de distribución siguen nuestros datos. Sin embargo, si tenemos una idea de cuál podría ser, es posible aproximar los parámetros de los que depende solo viendo el comportamiento gráfico de la distribución. Esto es posible gracias al algunos valores característicos de las distribuciones llamados **momentos**.\n",
    "\n",
    "Los más utilizados son los llamados *primeros momentos*, donde aparecen la esperanza, varianza, asimetría y curtosis, entre otras.\n",
    "\n",
    "### 6.1 Distribuciones discretas\n",
    "\n",
    "Para una variable aleatoria discreta definida sobre un espacio muestral $\\Omega$ con función densidad $f_X$, se define su **esperanza** (*expected value*) como\n",
    "\n",
    "$$\\mathbb{E}[X]=\\sum_{k\\in\\Omega}k\\cdot f_X(k)=\\mu$$\n",
    "\n",
    "Ésta se interpreta como el valor que se espera obtener la mayor cantidad de veces en un experimento realizado de forma sucesiva *ad infinitum*.\n",
    "\n",
    "Se define la **varianza** (*variance*) como\n",
    "\n",
    "$$\\mathbb{E}[(X-\\mu)^2]=\\sum_{k\\in\\Omega}(k-\\mu)^2\\cdot f_X(k)=\\mathbb{E}[X^2]-\\mu^2=\\sigma^2$$\n",
    "\n",
    "y se interpreta como el grado de dispersión que se espera tener de los datos, es decir, qué tan \"repartidos\" están los resultados.\n",
    "\n",
    "Se define la **asimetría** (*skewness*) como\n",
    "\n",
    "$$\\mathbb{E}\\left[\\left(\\frac{X-\\mu}{\\sigma}\\right)^3\\right]=\\sum_{k\\in\\Omega} \\left(\\frac{k-\\mu}{\\sigma}\\right)^3\\cdot f_X(k)=\\frac{\\mathbb{E}\\left[X^3\\right]-3\\mu\\sigma^2-\\mu^3}{\\sigma^3}=\\gamma$$\n",
    "\n",
    "que puede interpretarse como el grado de distancia entre las regiones con mayor densidad respecto de un eje de simetría, o bien como qué tan \"desbalanceada\" está la función densidad.\n",
    "\n",
    "Finalmente, la **curtosis** (*kurtosis*) como\n",
    "\n",
    "$$\\mathbb{E}\\left[\\left(\\frac{X-\\mu}{\\sigma}\\right)^4\\right]=\\kappa$$\n",
    "\n",
    "y mide la propensión de la distribución a generar datos muy poco frecuentes (*outliers*).\n",
    "\n",
    "Si bien existe una fórmula cerrada para cada uno de estos momentos (y aquellos de orden superior), no es tan frecuente el uso de otros fuera de los listados, entre otras razones ya que las expresiones obtenidas no son muy compactas.\n",
    "\n",
    "Como ejercicio, puede buscar la lista de distribuciones discretas vistas en la clase anterior y obtener una expresión para cada momento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerías\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# En los siguientes bloques, se evaluará de forma explícita las pdf y CDF dadas, y también se\n",
    "# aproximará mediante muestreos aleatorios para las distribuciones correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo exacto de esperanza\n",
    "\n",
    "# Cálculo exacto de varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimador insesgado para la esperanza sum(xn)/n\n",
    "\n",
    "# Estimador insesgado para la varianza sum((xn-mu)**2)/(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Distribuciones continuas\n",
    "\n",
    "Similarmente al caso discreto, si se tiene una variable aleatoria continua $X$ definida en un espacio muestral $\\Omega$, podemos definir sus momentos de forma análoga a lo anterior:\n",
    "\n",
    "$$\\mathbb{E}[X]=\\int_{\\Omega}x\\cdot f_X(x)dx=\\mu$$\n",
    "\n",
    "$$\\mathbb{E}[(X-\\mu)^2]=\\int_{\\Omega}(x-\\mu)^2\\cdot f_X(x)dx=\\sigma^2$$\n",
    "\n",
    "$$\\mathbb{E}\\left[\\left(\\frac{X-\\mu}{\\sigma}\\right)^3\\right]=\\int_{\\Omega} \\left(\\frac{x-\\mu}{\\sigma}\\right)^3\\cdot f_X(x)dx=\\gamma$$\n",
    "\n",
    "$$\\mathbb{E}\\left[\\left(\\frac{X-\\mu}{\\sigma}\\right)^4\\right]=\\kappa$$\n",
    "\n",
    "La interpretación en todos los casos es la misma, aunque siempre se debe tener la precaución de hacer la distinción entre la naturaleza discreta y la continua para evitar errores en la lectura de datos.\n",
    "\n",
    "También se propone como ejercicio buscar los momentos de las distribuciones continuas vistas la clase anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Teorema del Límite Central\n",
    "\n",
    "Este teorema justifica algunos supuestos que se asumen en ciertos estudios de índole estadístico. A grandes rasgos, establece que un mismo experimento realizado múltiples veces de forma independiente (es decir, que un resultado no debe afectar o verse afectado por otro) tenderá a tener valores promedio cercanos a como se comporta una distribución normal. Por lo tanto, los valores intermedios, tendrán mayor peso estadístico que los valores extremos.\n",
    "\n",
    "Matemáticamente se encuncia como que si se tiene una sucesión de variables aleatorias $\\{X_n\\}_n$ independientes e idénticamente distribuidas (iid), todas con esperanza $\\mu$ y variaza $\\sigma^2$, entonces\n",
    "\n",
    "$$\\mathbb{P}\\left[\\frac{(X_1-\\mu)+(X_2-\\mu)+\\ldots+(X_n-\\mu)}{\\sqrt{n\\sigma^2}}\\le z\\right]=\\Phi(z)$$\n",
    "\n",
    "donde $\\Phi(z)=\\displaystyle\\frac{1}{\\sqrt{2\\pi}}\\int_{-\\infty}^ze^{-\\frac{x^2}{2}}dx$ (distribución normal con media $0$ y varianza $1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestras\n",
    "n = 2500\n",
    "\n",
    "# muestreo según alguna distribución\n",
    "avg = []\n",
    "for i in range(2,n):\n",
    "    a = np.random.uniform(1,7,i)\n",
    "    avg.append(np.average(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graficar histograma\n",
    "def clt(current):\n",
    "    \n",
    "    plt.cla()\n",
    "    if current == n: \n",
    "        a.event_source.stop()\n",
    "\n",
    "    plt.hist(avg[0:current], bins=50, edgecolor='k')\n",
    "\n",
    "    plt.gca().set_title('Valor esperado')\n",
    "    plt.gca().set_xlabel('Promedio de experimentos')\n",
    "    plt.gca().set_ylabel('Frecuencia')\n",
    "\n",
    "    plt.annotate('Experimento = {}'.format(current), [3,27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "a = animation.FuncAnimation(fig, clt, interval=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Métodos Monte-Carlo\n",
    "\n",
    "Los métodos Monte-Carlo son algoritmos de diversa índole, cuya heurística incorpora pasos en los que hay grados de incerteza, los que son aprovechados en cada programa para realizar cálculos sin necesidad de establecer relaciones muy complejas.\n",
    "\n",
    "Ejemplos de su uso hay varios, aunque los más populares se encuentran en el análisis de sensibilidad de funciones (una forma indirecta de cálculo de derivada), en el cálculo de integrales numéricas (para conocer áreas, volúmenes, probabilidades) y en la exploración de dominios en general (llamados paseos aleatorios). En esta parte del curso, abordaremos las dos últimas, pues la parte de derivación ya fue vista con otros métodos. Sin embargo, eventualmente haremos referencia al análisis de sensibilidad de modelos.\n",
    "\n",
    "### 8.1 Integración Numérica\n",
    "\n",
    "Supongamos que deseamos conocer el que se encuentra limitada en un dibujo y que éste puede expresarse a través de funciones. Si hacemos \"llover\" puntos sobre este dibujo, una forma muy sencilla de aproximar el área es contar la cantidad de puntos que cayó dentro del dibujo, ignorando los que no. Esto nos da una fórmula bastante sencilla para la aproximación, suponiendo una cantidad robusta de puntos:\n",
    "\n",
    "$$A_{\\textrm{dibujo}}=A_{\\textrm{cuadro}}\\cdot\\frac{|\\textrm{Puntos dentro}|}{|\\textrm{Puntos muestra}|}$$\n",
    "\n",
    "Por lo general, para recoger la muestra de puntos, se suele limitar el contexto en que se encuentra el dibujo y se utiliza distribuciones apropiadas a la figura, aunque siempre es posible utilizar simplemente la distribución uniforme. La ventaja de usar otras distribuciones está en obtener convergencia al resultado real en menor cantidad de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir alguna función y graficarla con limites fijos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimar área\n",
    "\n",
    "A_cuadro = (b - a) * (d - c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Paseos Aleatorios\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios\n",
    "\n",
    "**1.-** Para la lista de distribuciones mencionadas, averigüe el significado y el valor de los siguientes términos:\n",
    "\n",
    "**a)** Esperanza (*mean*)\n",
    "<br>\n",
    "**b)** Varianza (*variance*)\n",
    "<br>\n",
    "**c)** Mediana (*median*)\n",
    "<br>\n",
    "**d)** Moda (*mode*)\n",
    "<br>\n",
    "<br>\n",
    "¿Cómo interpreta estos valores?\n",
    "\n",
    "**2.-** Para las distribuciones vistas, realice el siguiente experimento:\n",
    "\n",
    "**a)** Encuentre el valor de su esperanza\n",
    "<br>\n",
    "**b)** Realice un muestreo aleatorio de tamaño $N$ a su elección (ojalá $N\\ge100$).\n",
    "<br>\n",
    "**c)** Calcule y grafique la cantidad $\\frac{1}{k}\\sum_{i=1}^kx_i$, para $k$ desde $1$ hasta $N$. Puede utilizar los comandos\n",
    "```Python\n",
    "# x tiene que estar definido desde antes como una muestra aleatoria de su elección, con N puntos\n",
    "suma = []\n",
    "for i in range(N):\n",
    "    s = np.mean(x[:i])\n",
    "    suma.append(s)\n",
    "```\n",
    "Superponga a este gráfico el valor constante encontrado para la esperanza. ¿Cómo se comportan estas cantidades?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
